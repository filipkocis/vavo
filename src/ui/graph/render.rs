use glyphon::{TextAtlas, TextRenderer, Viewport};
use winit::dpi::PhysicalSize;

use crate::core::graph::*;
use crate::prelude::*;

use crate::render_assets::{BindGroup, Buffer, RenderAssets};
use crate::ui::mesh::{UiMesh, UiMeshTransparent};

use super::storage::UiTransformStorage;

/// Ui graph node rendering system
pub fn ui_render_system(
    graph_ctx: CustomRenderGraphContext,

    world: &mut World,
    window: Res<Window>,

    // resources
    mut buffers: ResMut<RenderAssets<Buffer>>,
    mut bind_groups: ResMut<RenderAssets<BindGroup>>,

    // text resources
    text_renderer: Res<TextRenderer>,
    text_atlas: Res<TextAtlas>,
    viewport: Res<Viewport>,

    // holds the ui mesh - vertices and indices for every ui node
    ui_mesh: Res<UiMesh>,
    ui_mesh_transparent: Res<UiMeshTransparent>,
    // holds the transform of every ui node
    ui_transforms: Res<UiTransformStorage>,

    mut camera_query: Query<
        (EntityId, &Camera),
        (With<Transform>, With<Projection>, With<Camera3D>),
    >,
) {
    let ui_mesh = buffers.get_by_resource(&ui_mesh, world, true);
    let ui_mesh_transparent = buffers.get_by_resource(&ui_mesh_transparent, world, true);

    // find active camera
    let active_camera = camera_query
        .iter_mut()
        .into_iter()
        .filter(|(_, c)| c.active)
        .take(1)
        .next();
    let camera_bind_group;
    if let Some((id, camera)) = active_camera {
        camera_bind_group = bind_groups.get_by_entity(id, camera, world);
    } else {
        return;
    }

    // prepare attachments
    let color_attachment = Some(wgpu::RenderPassColorAttachment {
        view: unsafe { &*graph_ctx.color_target.expect("ui color target is None") },
        depth_slice: None,
        resolve_target: None,
        ops: wgpu::Operations {
            load: wgpu::LoadOp::Load,
            store: wgpu::StoreOp::Store,
        },
    });

    let mut depth_stencil = wgpu::RenderPassDepthStencilAttachment {
        view: unsafe { &*graph_ctx.depth_target.expect("ui depth target is None") },
        depth_ops: Some(wgpu::Operations {
            load: wgpu::LoadOp::Load,
            store: wgpu::StoreOp::Store,
        }),
        stencil_ops: None,
    };

    let pipeline = unsafe { &*graph_ctx.node }
        .data
        .pipeline
        .as_ref()
        .expect("Pipeline should have been generated by now")
        .render_pipeline();
    let mut encoder = ctx.renderer.encoder();

    // opaque render pass
    {
        let mut render_pass = encoder.begin_render_pass(&wgpu::RenderPassDescriptor {
            label: Some("ui opaque render pass"),
            color_attachments: std::slice::from_ref(&color_attachment),
            depth_stencil_attachment: Some(depth_stencil.clone()),
            occlusion_query_set: None,
            timestamp_writes: None,
        });

        draw_ui_render_pass(
            &mut render_pass,
            pipeline,
            window.size(),
            ui_transforms.bind_group(),
            &camera_bind_group,
            &ui_mesh,
        );
    } // necessary to drop render_pass before second pass

    // dont store depth for transparent objects
    depth_stencil.depth_ops = Some(wgpu::Operations {
        load: wgpu::LoadOp::Load,
        store: wgpu::StoreOp::Discard,
    });

    // transparent render pass
    let mut render_pass = encoder.begin_render_pass(&wgpu::RenderPassDescriptor {
        label: Some("ui transparent render pass"),
        color_attachments: &[color_attachment],
        depth_stencil_attachment: Some(depth_stencil),
        occlusion_query_set: None,
        timestamp_writes: None,
    });

    draw_ui_render_pass(
        &mut render_pass,
        pipeline,
        window.size(),
        ui_transforms.bind_group(),
        &camera_bind_group,
        &ui_mesh_transparent,
    );

    // render text
    text_renderer
        .render(&text_atlas, &viewport, &mut render_pass)
        .unwrap();
}

fn draw_ui_render_pass(
    render_pass: &mut wgpu::RenderPass,
    pipeline: &wgpu::RenderPipeline,
    window_size: PhysicalSize<u32>,
    ui_transforms_bind_group: &wgpu::BindGroup,
    camera_bind_group: &BindGroup,
    ui_mesh: &Buffer,
) {
    if ui_mesh.num_indices == 0 {
        return;
    }

    let vertex_buffer = ui_mesh
        .vertex
        .as_ref()
        .expect("UiMesh buffer should have a vertex buffer");
    let index_buffer = ui_mesh
        .index
        .as_ref()
        .expect("UiMesh buffer should have an index buffer");

    render_pass.set_pipeline(pipeline);

    // push constants
    render_pass.set_push_constants(
        wgpu::ShaderStages::VERTEX,
        0,
        bytemuck::cast_slice(&[(window_size.width as f32), (window_size.height as f32)]),
    );

    // bind groups
    render_pass.set_bind_group(0, ui_transforms_bind_group, &[]);
    render_pass.set_bind_group(1, camera_bind_group, &[]);

    // vertex and index buffers
    render_pass.set_vertex_buffer(0, vertex_buffer.slice(..));
    render_pass.set_index_buffer(index_buffer.slice(..), wgpu::IndexFormat::Uint32);

    // draw
    render_pass.draw_indexed(0..ui_mesh.num_indices, 0, 0..1);
}
